{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook our goal is to analyze the problem reported on PKG-2277 whew some blocks of authors contain huge profiles related to one OAId but only one S2Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "AUTHOR_PATH = '../data/ha-zhang-single/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    \"\"\"Parse jsonl to list of dicts\"\"\"\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    return [json.loads(line) for line in lines]\n",
    "\n",
    "\n",
    "def get_signatures(ap_results):\n",
    "    \"\"\"Given the author profile results get all signatures\"\"\"\n",
    "    signatures = []\n",
    "    for profile in ap_results:\n",
    "        signatures += profile['signatureIds']\n",
    "    return signatures\n",
    "\n",
    "\n",
    "def fill_dmatrix(distances, signature_list):\n",
    "    \"\"\"Given distances jsonl and list of signatures fill the distance matrix\"\"\"\n",
    "    dmatrix = np.zeros(shape=(len(signature_list), len(signature_list)))\n",
    "\n",
    "    signature_to_idx = {\n",
    "        signature: idx for idx, signature in enumerate(signature_list)\n",
    "    }\n",
    "\n",
    "    for distance in distances:\n",
    "        sig1 = distance['signatureId1']\n",
    "        sig2 = distance['signatureId2']\n",
    "        d = distance['distance']\n",
    "        row = signature_to_idx[sig1]\n",
    "        column = signature_to_idx[sig2]\n",
    "        dmatrix[row, column] = d\n",
    "\n",
    "    dmatrix = dmatrix.T + dmatrix # Transpose to fill symetric elements\n",
    "    return dmatrix, signature_to_idx\n",
    "\n",
    "\n",
    "def get_features(sig_id, features):\n",
    "    \"\"\"Retrieve all feature vectors realated to the given signature\"\"\"\n",
    "    feature_vectors = []\n",
    "    for feature_entry in features:\n",
    "        if feature_entry['signatureId1'] == sig_id or feature_entry['signatureId2'] == sig_id:\n",
    "            feature_vectors.append(feature_entry['features'])\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_results = read_jsonl(path=os.path.join(AUTHOR_PATH, 'results.json'))\n",
    "distances = read_jsonl(path=os.path.join(AUTHOR_PATH, 'distances.json'))\n",
    "signatures = get_signatures(ap_results)\n",
    "dmatrix, signature_to_idx = fill_dmatrix(distances, signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one profile in the results that contains more than 6k signatures, lets find it:\n",
    "\n",
    "for entry in ap_results:\n",
    "    if len(entry[\"signatureIds\"]) >= 6_000:\n",
    "        target_profile = entry[\"signatureIds\"]\n",
    "        break\n",
    "\n",
    "target_profile = set(target_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_info = read_jsonl(path=os.path.join(AUTHOR_PATH, 'features.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will filter distances that are calculated for pairs that both signatures belong in the target profile\n",
    "\n",
    "filterted_distances = [\n",
    "    distance['calcType'] for distance in distance_info \\\n",
    "        if distance['signatureId1'] in target_profile and distance['signatureId2'] in target_profile\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['orcid'], dtype='<U5'), array([23601885]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(filterted_distances, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 100% of the aprox. 23 million pairs have distances calculated with the orcId rule. That said, we are certain that the problem occurs during the application of the orcId rule and ml model does not take any part in the distance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2and",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
