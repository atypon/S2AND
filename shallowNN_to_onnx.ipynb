{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fac0a3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import torch, pickle, shap\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from joblib import load, dump\n",
    "\n",
    "\n",
    "nn_model = torch.load('models/shallowNN.pt')\n",
    "ensemble_model = load('models/ensemble.joblib')\n",
    "\n",
    "with open('cached/numpy_arrays.pickle', 'rb') as f:\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad9a11",
   "metadata": {},
   "source": [
    "### Customize Foward Pass\n",
    "\n",
    "\n",
    "As last logistic regression layer is sklearn object, we first convert it to a complet pytorch neural network.\n",
    "\n",
    "After testing the conversion, we convert the whole model to onnx format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785310d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.nn_model = torch.load('models/shallowNN.pt')\n",
    "        self.ensemble_model = load('models/ensemble.joblib')\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X_nn = X[:,:-3]\n",
    "        distance = self.nn_model.predict(X_nn)\n",
    "        distance = np.expand_dims(distance, axis=1)\n",
    "        X_ensemble = np.concatenate((X[:,-3:], distance),axis=1)\n",
    "        return self.ensemble_model.predict_proba(X_ensemble)[:,0]\n",
    "    \n",
    "    \n",
    "class TorchEnsemble(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(TorchEnsemble, self).__init__()        \n",
    "        self.nn_model = torch.load('models/shallowNN.pt')\n",
    "        \n",
    "        lr_layer = load('models/ensemble.joblib')\n",
    "        \n",
    "        self.ensemble_model = nn.Sequential(\n",
    "            nn.Linear(in_features=4, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.ensemble_model[0].weight = nn.Parameter(torch.FloatTensor(lr_layer.coef_))\n",
    "            self.ensemble_model[0].bias = nn.Parameter(torch.FloatTensor(lr_layer.intercept_))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = torch.Tensor(X)\n",
    "        X1 = X[:,:-3]\n",
    "        similarity = self.nn_model.forward(X1)\n",
    "        similarity = torch.nn.functional.sigmoid(similarity).unsqueeze(1)\n",
    "        X2 = torch.cat((X[:,-3:], similarity), dim=1)\n",
    "        return 1-self.ensemble_model(X2)\n",
    "    \n",
    "model1 = Ensemble()\n",
    "model2 = TorchEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388437c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n"
     ]
    }
   ],
   "source": [
    "y1 = model1.forward(X_train)\n",
    "y2 = model2.forward(X_train).detach().squeeze(1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fb7e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    np.testing.assert_array_almost_equal(y1,y2, decimal=6)\n",
    "    print('Test passed')\n",
    "except:\n",
    "    print('Test failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67775406",
   "metadata": {},
   "source": [
    "As the test is passed, convertion to complete Pytorch network is successful. Now we convert Pytorch to ONNX and we test again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446cb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n"
     ]
    }
   ],
   "source": [
    "torch_model = TorchEnsemble()\n",
    "\n",
    "# Input to the model\n",
    "torch_out = torch_model.forward(X_train)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(torch_model,               # model being run\n",
    "                  torch.FloatTensor(X_train),     # model input (or a tuple for multiple inputs)\n",
    "                  \"models/ensemble.onnx\",    # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1a63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "y_target = model2.forward(torch.Tensor(X_train)).detach().numpy()\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"models/ensemble.onnx\")\n",
    "inputs = {'input' : X_train.astype(np.float32)}\n",
    "y_onnx = ort_session.run(None, inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0eab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    np.testing.assert_array_almost_equal(y_target,y_onnx, decimal=6)\n",
    "    print('Test passed')\n",
    "except:\n",
    "    print('Test failed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
